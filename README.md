![Firefly create a an abstract image that shows how an alchemy can detect the tone of a text message, ](https://github.com/user-attachments/assets/9969b3ee-0770-450f-84a5-15a493be62c7)

# ToneAlchemy

The **ToneAlchemy AI** application allows users to analyze and modify the tone of text using the **window.ai API**, which leverages the **Google Gemini Nano Model**. This application runs directly within the Chrome browser, providing real-time feedback on text tone and enabling tone modifications via user interface.

## Features

- **Text Analysis**: Analyze the tone of the provided text and receive ratings for various predefined tones.
- **Tone Change**: Modify the tone of the text to a selected tone using the window.ai API.

## Example
#### Input text

> Our systems are currently impacted by a Microsoft outage, which is
> also affecting other companies. During this time booking, check-in,
> access to your boarding pass, and some flights may be impacted. We
> appreciate your patience.

#### Output (analysis):
> Apologetic: 10,
> Serious: 9,
> Direct: 8,
> Formal: 7,
> Thankful: 6,
> Authoritative: 5,
> Empathetic: 4,
> Persuasive: 3,
> Friendly: 2

#### Updated tone (to Informal)
> "Oh snap! Our digital peeps are battling a Microsoft hiccup, sending chaos across the business world.
> As the situation develops, things like booking, check-ins, boarding passes,
> and even some flights might get bumped or delayed. Hang tight, folks, we're on it!"

## Tech Stack

- **window.ai API**: Utilizes Google's Gemini Nano LLM for text analysis and tone modification.
- **Preact**: Lightweight alternative to React for building user interfaces.
- **Tailwind CSS**: For responsive and customizable styling.

## Usage
- The `window.ai` API currently works only on latest version of Google Chrome Canary and Chrome Dev (128.0 and above) and disabled by default.
- Under `chrome://flags`, set `#optimization-guide-on-device-model` to `Enabled BypassPerfRequirement` and `#prompt-api-for-gemini-nano` to `Enabled`.
- Under `chrome://components`, ensure `Optimization Guide On Device Model` is installed and version is not `0.0.0.0`

## Observations
- The analysis can be inconsistent at times, which is expected given the model's small size and early development stage. Future updates may improve this.
- Model inference works offline since it runs in the browser. However, the application must ensure the necessary scripts are available offline.
- The model's analysis time increases with complexity, which is expected as it runs on a local device.

## Disclaimer: 
Over 95% of this code was generated by LLMs like **Claude 3.5 Sonnet and ChatGPT**, as it was intended for rapid prototyping.
